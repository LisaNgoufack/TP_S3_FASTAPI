= TP3 - API Analyse Multivariée : PCA & Clustering
:author: NGOUFACK Judith
:revdate: 11 Février 2026
:toc: left
:toclevels: 3
:numbered:
:icons: font
:source-highlighter: rouge

== Introduction

Ce projet implémente une API REST pour l'analyse multivariée, exposant deux méthodes fondamentales :

* PCA (Analyse en Composantes Principales) : Réduction de dimensionnalité
* K-means : Clustering non-supervisé

L'objectif est de fournir des résultats *interprétables* et non pas uniquement des tableaux de nombres bruts.

== Architecture

=== Structure du projet

TP3_API_MV/
├── app/
│   ├── main.py                 # Point d'entrée FastAPI
│   ├── routers/
│   │   └── mv.py               # Routes API
│   └── services/
│       └── mv_service.py       # Logique métier


=== Technologies

* FastAPI : Framework web avec validation automatique
* Pandas : Manipulation de données
* NumPy : Calculs matriciels et génération aléatoire
* Scikit-learn : PCA, K-means, StandardScaler, Silhouette
* Pydantic : Validation de schémas

== Fonctionnalités implémentées

=== 1. Génération de datasets (POST /mv/dataset-generate)

Génère un dataset avec structure contrôlée :

* 8 variables numériques : x1 à x8
* 3 clusters simulés : Centres distincts pour faciliter la détection
* Colinéarité : x5 ≈ x1 + bruit (test de redondance)
* Valeurs manquantes : 2-5% par variable

Méthode de génération des clusters :

[source,python]

# Cluster 1 : centre (0, 0, ...)
cluster1 = rng.normal(loc=[0]*8, scale=1, size=(n//3, 8))

# Cluster 2 : centre (5, 5, ...)
cluster2 = rng.normal(loc=[5]*8, scale=1, size=(n//3, 8))

# Cluster 3 : centre (-3, -3, ...)
cluster3 = rng.normal(loc=[-3]*8, scale=1, size=(n//3, 8))

# Colinéarité
x5 = x1 + bruit(μ=0, σ=0.3)


=== 2. PCA (POST /mv/pca/fit_transform)

Analyse en composantes principales avec résultats enrichis.

Paramètres :

* n_components : 2 à 5 (nombre de composantes à extraire)
* scale : true/false (standardisation Z-score avant PCA)

Résultats retournés :

1. Projection : Coordonnées de chaque observation dans l'espace réduit

[source,json]

"projection": [
  {"PC1": -0.804, "PC2": 0.045},
  {"PC1": -0.633, "PC2": -0.151}
]


2. Variance expliquée*: Pourcentage de variance capturé par chaque PC

[source,json]

"eplained_variance_ratio": {
  "PC1": 0.933,  // 93.3% de la variance
  "PC2": 0.020   // 2.0% supplémentaire
},
"total_variance_explained": 0.953  // 95.3% total
----

3. *Loadings* : Contribution de chaque variable à chaque composante
+
[source,json]

"loadings": {
  "PC1": {
    "x1": 0.356,  // x1 contribue à 35.6% à PC1
    "x2": 0.352,
    ...
  },
  "PC2": {
    "x1": 0.570,  // x1 contribue fortement à PC2
    "x5": 0.576,  // x5 aussi (colinéarité détectée)
    "x3": -0.501  // x3 en opposition
  }
}


Interprétation automatique :

L'API fournit un message clair : _"Les 2 premières composantes expliquent 95.3% de la variance totale"_

=== 3. K-means (POST /mv/cluster/kmeans)

Clustering avec métriques de qualité.

Paramètres :

* k : 2 à 6 (nombre de clusters)
* scal` : true/false (standardisation avant clustering)

Résultats retournés :

1. Labels : Assignation cluster pour chaque observation

[source,json]

"labels": [2, 2, 0, 0, 1, 1, ...]  // 83 valeurs


2. Centroids : Centre de chaque cluster (dans espace original si scaled)

[source,json]

"centroids": [
  {"x1": 4.71, "x2": 4.92, "x3": 5.39, ...},  // Cluster 0
  {"x1": -2.95, "x2": -2.61, "x3": -3.02, ...}, // Cluster 1
  {"x1": 0.08, "x2": -0.01, "x3": 0.01, ...}   // Cluster 2
]


3. Tailles des clusters

[source,json]

"cluster_sizes": {
  "cluster_0": 30,
  "cluster_1": 25,
  "cluster_2": 28
}


4. Métriques de qualité

[source,json]

"silhouette_score": 0.630,  // Score entre -1 et 1 (0.630 = bon)
"inertia": 56.96            // Variance intra-cluster


Interprétation automatique :

L'API fournit : _"Silhouette score: 0.630"_ indiquant un bon clustering.

=== 4. Rapport interprétable (GET /mv/report/{dataset_id})

Génère automatiquement un rapport d'analyse multivariée.

Contenu du rapport :

1. Interprétation PCA : Top 3 variables sur PC1 et PC2

[source,json]

"PC1_top_positive": {
  "x4": 0.356,  // Variables à contribution positive
  "x1": 0.356,
  "x8": 0.355
},
"PC2_top_positive": {
  "x5": 0.576,  // x1 et x5 fortement corrélés
  "x1": 0.570
},
"PC2_top_negative": {
  "x3": -0.501  // x3 en opposition à x1/x5
}

2. Suggestion de clustering : Test k=2 à k=5 avec inertie

[source,json]

"inertias_by_k": {
  "k=2": 133.54,
  "k=3": 56.96,   //  Fort drop (coude)
  "k=4": 49.89,
  "k=5": 46.60
}

→ Suggestion : k=3 optimal (méthode du coude)

3. Info dataset : Échantillons valides après nettoyage

[source,json]
----
"dataset_info": {
  "n_samples": 83,            // Après suppression NA
  "n_features": 8,
  "missing_rows_removed": 17  // 17% de NA
}

== Résultats

=== Exemple de workflow complet

[cols="1,3", options="header"]
|===
|Étape |Résultat

|Génération
|100 lignes, 8 colonnes, 3 clusters simulés

|PCA (n=2)
|PC1 = 93.3%, PC2 = 2.0% → 95.3% variance totale

|K-means (k=3)
|Clusters de tailles 28, 30, 25 - Silhouette = 0.630

|Report
|x1 et x5 corrélées (colinéarité détectée), k=3 optimal
|===

=== Validation de la colinéarité

La colinéarité x5 ≈ x1 est bien détectée :

* PC2 loadings : x1 = 0.570, x5 = 0.576 (très proches)
* Interprétation : PC2 capture la variance commune à x1 et x5

=== Qualité du clustering

* Silhouette score : 0.630 (bon, proche de 1)
* Clusters équilibrés : 28, 30, 25 (pas de cluster minuscule)
* Centroids distincts : Centres espacés (facilite séparation)

== Résultats interprétables (non bruts)

L'API ne renvoie PAS uniquement des arrays numpy, mais des structures enrichies :

[cols="2,3,3", options="header"]
|===
|Endpoint |Arrays bruts évités |Interprétation ajoutée

|PCA
|np.ndarray de projections
|{"PC1": ..., "PC2": ...} + variance expliquée + loadings nommés

|K-means
|`np.array` de labels
|Labels + centroids structurés + tailles clusters + silhouette

|Report
|Matrices de loadings
|Top 3 variables par PC + suggestion k optimal + variance 2PC
|===

Exemple de transformation :

Brut (scikit-learn) :
[source,python]

pca.components_  # Array 2D non nommé


Interprétable (API) :
[source,json]

"loadings": {
  "PC1": {"x1": 0.356, "x2": 0.352, ...},
  "PC2": {"x1": 0.570, "x5": 0.576, ...}
}


== Conformité au cahier des charges

[cols="2,1,1", options="header"]
|===
|Critère |Poids |Statut

|Router mv + service multivarié + schémas Pydantic
|Livrable
| COMPLET

|Résultats interprétables (pas uniquement des arrays bruts)
|Livrable
| EXCELLENT

|PCA fit_transform (projection, variance, loadings)
|Endpoint
| COMPLET

|K-means (labels, centroids, silhouette)
|Endpoint
| COMPLET

|Report interprétable (top loadings, tailles clusters)
|Endpoint
| COMPLET

|Dataset avec 3 clusters + colinéarité
|Dataset
| COMPLET
|===

== Schémas Pydantic

L'API utilise 3 schémas de validation :

[source,python]

class DatasetGenerateRequest(BaseModel):
    phase: str = "mv"
    seed: int
    n: int

class PCARequest(BaseModel):
    dataset_id: str
    n_components: int = 2  # 2 à 5
    scale: bool = True

class KMeansRequest(BaseModel):
    dataset_id: str
    k: int = 3  # 2 à 6
    scale: bool = True


Validation automatique :

* n_components hors [2, 5] → Erreur 404
* k hors [2, 6] → Erreur 404
* dataset_id invalide → Erreur 404

== Gestion des valeurs manquantes

Stratégie adoptée : Suppression des lignes avec NA

* Avant : 100 lignes générées
* Après : 83 lignes valides (17% supprimées)

Justification :

* PCA et K-means nécessitent matrices complètes
* Imputation pourrait biaiser la structure de clusters
* Dataset de test → suppression acceptable

Alternative (non implémentée) : Imputation par moyenne/médiane

== Choix techniques

=== Standardisation (scale=true)

Pourquoi standardiser ?

* Variables sur échelles différentes → Biais vers variables à grande variance
* PCA sans standardisation → Domination par variables de grande amplitude
* K-means sans standardisation → Distance euclidienne biaisée

Exemple :

Sans standardisation : Variable [0, 1000] domine variable [0, 1]

Avec standardisation : Toutes variables μ=0, σ=1

=== Silhouette score

Interprétation :

* Score > 0.7 : Clustering fort
* Score 0.5-0.7 : Clustering acceptable
* Score < 0.3 : Clustering faible

Résultat obtenu : 0.630 (acceptable/bon)

== Conclusion

L'API implémente avec succès l'analyse multivariée via API REST :

*  PCA complète (projection, variance, loadings)
*  K-means robuste (labels, centroids, qualité)
*  Rapport automatique (top loadings, suggestion k)
*  Résultats interprétables (structures enrichies)
*  Dataset contrôlé (3 clusters, colinéarité)
*  Architecture modulaire (router/service)
*  Validation Pydantic

Les résultats ne sont *jamais* des arrays bruts mais toujours enrichis d'interprétations et de métriques de qualité.

== Annexes

=== A. Exemple de résultats PCA

[source,json]

{
  "explained_variance_ratio": {
    "PC1": 0.933,
    "PC2": 0.020
  },
  "loadings": {
    "PC1": {"x4": 0.356, "x1": 0.356, ...},
    "PC2": {"x5": 0.576, "x1": 0.570, ...}
  }
}


=== B. Exemple de résultats K-means

[source,json]

{
  "cluster_sizes": {"cluster_0": 30, "cluster_1": 25, "cluster_2": 28},
  "silhouette_score": 0.630,
  "quality": "Silhouette score: 0.630"
}

=== C. Colinéarité détectée

PC2 loadings montrent x1 et x5 fortement corrélées (0.570 et 0.576) confirmant x5 ≈ x1 + bruit.